#,trainThreads = 8
,reportProgress = rxGetOption('reportProgress')
,blocksPerRead = rxGetOption('blocksPerRead')
,rowSelection = NULL
)
)
# summary(SDCAModel) #The Stochastic Dual Coordinate Ascend Model
# SDCAModel$coefficients
} else {
EnsembleofDecisionTreesModel <- readRDS("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS")
}
if (SavePredictionModel) {
saveRDS(EnsembleofDecisionTreesModel, "C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS")
}
SavePredictionModel
if (MakePredictions) {
## Applying the Predictions ##
rxPredict(modelObject = EnsembleofDecisionTreesModel,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "tmp.xdf", sep = ""),
overwrite = TRUE
)
if (type == "binary") {
tmpVarInfo <- list(
PredictedLabel = list(newName = "SDCA_Prediction"),
Probability.1 = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
varsToKeep = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
} else {
tmpVarInfo <- list(
Score = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
transforms = list(SDCA_Prediction = ifelse(SDCA_PredictionReal >= 0.5, 1, 0)),
overwrite = TRUE
)
}
CurVarNamesTest <- rxSummary(~., data = paste(strXDF, "Test_DS.xdf", sep = ""))$sDataFrame[[1]]
if ("SDCA_PredictionReal" %in% (CurVarNamesTest)) {
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "tmp3.xdf", sep = ""),
varsToDrop = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp3.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
file.remove(paste(strXDF, "tmp3.xdf", sep = ""))
}
remove(CurVarNamesTest)
rxMerge(inData1 = paste(strXDF, "Test_DS.xdf", sep = ""),
inData2 = paste(strXDF, "tmp2.xdf", sep = ""),
outFile = paste(strXDF, "tmp.xdf", sep = ""),
type = "oneToOne",
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
remove(tmpVarInfo)
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
file.remove(paste(strXDF, "tmp2.xdf", sep = ""))
if (!(StatisticsMode)) {
tmp <- rxDataStep(inData = Test_DS, varsToKeep = c("ID_Erga", "SDCA_PredictionReal", "SDCA_Prediction"))
write.csv(tmp, file = paste(strXDF, "EnsembleofDecisionTrees_Results.csv", sep = ""), row.names = FALSE)
remove(tmp)
}
}
TestDataSummary <- rxSummary(~., data = Test_DS)$sDataFrame
TestColumnNames <- TestDataSummary$Name
if (ShowVariableInfo) {
TestVarInfo <- rxGetInfo(Test_DS, getVarInfo = TRUE, numRows = 0)$varInfo
}
if (StatisticsMode) {
## Creating and Viewing Statistics & Graphs ##
if (ShowStatistics) {
## Statistics ##
if (("SDCA_Prediction" %in% TestColumnNames) && ("Label" %in% TestColumnNames)) {
LabelPredictionExist <- TRUE
tmp <- rxCube(~ F(Label):F(SDCA_Prediction), data = paste(strXDF, "Test_DS.xdf", sep = ""))
StatisticsResults <- Statistics(tmp, 3, paste(strXDF, "Training_DS.xdf", sep = ""))
remove(tmp)
sink("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Functions/Sink.R") 	#Starting sink-ing to Sink.R file
print(StatisticsResults)
sink()			#Stopping sink-ing
} else {
LabelPredictionExist <- FALSE
}
}
if (ShowROCCurve) {
## Graphs ##
if (("SDCA_Prediction" %in% TestColumnNames) && ("Label" %in% TestColumnNames)) {
PredictionRealExist <- TRUE
if (ColumnsCombinations) { #REngine can't handle multiple Plot Windows, hence they should be saved as PNG and ran afterwards
png(filename = paste(strGraphs, "EnsembleofDecisionTreesModelROC.png", sep = "") , width = 615, height = 520, units = "px")
}
rxRocCurve(actualVarName = "Label",
predVarName = "SDCA_PredictionReal",
data = paste(strXDF, "Test_DS.xdf", sep = "")
)
if (ColumnsCombinations) { #REngine can't handle multiple Plot Windows, hence they should be saved as PNG and ran afterwards
dev.off()
}
} else {
PredictionRealExist <- FALSE
}
}
}
###########################
### Supervised Learning ###
###########################
if (!(file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS")) && (UseExistingModel)) {
RDSCreatedOutOfNecessity <- TRUE
} else {
RDSCreatedOutOfNecessity <- FALSE
}
###########################################################################
### 8) Creating a Classification Model using Ensemble of Decision Trees ###
###########################################################################
if ((!(UseExistingModel)) || (!file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS"))) {
## Creating the Model ##
rxDTreeElapsedTime <- system.time(
#Tweakable:
#--Variables
#--numTrees
#--numLeaves
#//To be left as is on this experiment (though tweakable if needed)\\#
#--type [binary/regression]
EnsembleofDecisionTreesModel <- rxFastForest(Label ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou + Skopos_Ergou + MelClientDelay + Mel_Kathisterisi_Pelati + MelDEHDelay + Mel_Kathisterisi_DEH + MelOthersDelay + Mel_Kathisterisi_Triton + Meres_Meletis + Sinergio_Meletis + Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis + Ektasi_Ergou + Anagi_YS + Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine + DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY + .rxCluster
, data = paste(strXDF, "Training_DS.xdf", sep = "")
,type = type
,numTrees = 50 #Specifies the total number of decision trees to create in the ensemble.By creating more decision trees, you can potentially get better coverage, but the training time increases. The default value is 100
,numLeaves = 10 #The maximum number of leaves (terminal nodes) that can be created in any tree. Higher values potentially increase the size of the tree and get better precision, but risk over-fitting and requiring longer training times. The default value is 20.
,numBins = round(min(1001, max(101, sqrt(n_Train)))) #this controls the maximum number of bins used for each variable. Managing the number of bins is important in controlling memory usage. The default is min(1001, max(101, sqrt(num of obs))). For small data sets with continuous predictors, you may find that you need to increase the maxNumBins to obtain models that resemble those from rpart.
,gainConfLevel = 0 #Tree fitting gain confidence requirement (should be in the range [0,1)). The default value is 0.
#,minSplit = 10 #Minimum number of training instances required to form a leaf. That is, the minimal number of documents allowed in a leaf of a regression tree, out of the sub-sampled data. A 'split' means that features in each level of the tree (node) are randomly divided. The default value is 10. Only the number of instances is counted even if instances are weighted.
#,exampleFraction = 0.7 #The fraction of randomly chosen instances to use for each tree. The default value is 0.7
#,featureFraction = 0.7 #The fraction of randomly chosen features to use for each tree. The default value is 1
#,splitFraction = 0.7 #The fraction of randomly chosen features to use on each split. The default value is 1
#,firstUsePenalty = 0 #The feature first use penalty coefficient. This is a form of regularization that incurs a penalty for using a new feature when creating the tree. Increase this value to create trees that don't use many features. The default value is 0.
#,trainThreads = 8
,reportProgress = rxGetOption('reportProgress')
,blocksPerRead = rxGetOption('blocksPerRead')
,rowSelection = NULL
)
)
# summary(SDCAModel) #The Stochastic Dual Coordinate Ascend Model
# SDCAModel$coefficients
} else {
EnsembleofDecisionTreesModel <- readRDS("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS")
}
if (SavePredictionModel) {
saveRDS(EnsembleofDecisionTreesModel, "C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/EnsembleofDecisionTreesModel.RDS")
}
if (MakePredictions) {
## Applying the Predictions ##
rxPredict(modelObject = EnsembleofDecisionTreesModel,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "tmp.xdf", sep = ""),
overwrite = TRUE
)
if (type == "binary") {
tmpVarInfo <- list(
PredictedLabel = list(newName = "SDCA_Prediction"),
Probability.1 = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
varsToKeep = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
} else {
tmpVarInfo <- list(
Score = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
transforms = list(SDCA_Prediction = ifelse(SDCA_PredictionReal >= 0.5, 1, 0)),
overwrite = TRUE
)
}
CurVarNamesTest <- rxSummary(~., data = paste(strXDF, "Test_DS.xdf", sep = ""))$sDataFrame[[1]]
if ("SDCA_PredictionReal" %in% (CurVarNamesTest)) {
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "tmp3.xdf", sep = ""),
varsToDrop = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp3.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
file.remove(paste(strXDF, "tmp3.xdf", sep = ""))
}
remove(CurVarNamesTest)
rxMerge(inData1 = paste(strXDF, "Test_DS.xdf", sep = ""),
inData2 = paste(strXDF, "tmp2.xdf", sep = ""),
outFile = paste(strXDF, "tmp.xdf", sep = ""),
type = "oneToOne",
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
remove(tmpVarInfo)
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
file.remove(paste(strXDF, "tmp2.xdf", sep = ""))
if (!(StatisticsMode)) {
tmp <- rxDataStep(inData = Test_DS, varsToKeep = c("ID_Erga", "SDCA_PredictionReal", "SDCA_Prediction"))
write.csv(tmp, file = paste(strXDF, "EnsembleofDecisionTrees_Results.csv", sep = ""), row.names = FALSE)
remove(tmp)
}
}
#This is always needed because TestColumnNames is used no matter what
#if ((ShowDataSummary) || (ShowVariableInfo)) {
#Updating the Column Names and Data Summary as new variables might have been introduced (e.g. predictions)
TestDataSummary <- rxSummary(~., data = Test_DS)$sDataFrame
TestColumnNames <- TestDataSummary$Name
#}
if (ShowVariableInfo) {
TestVarInfo <- rxGetInfo(Test_DS, getVarInfo = TRUE, numRows = 0)$varInfo
}
if (StatisticsMode) {
## Creating and Viewing Statistics & Graphs ##
if (ShowStatistics) {
## Statistics ##
if (("SDCA_Prediction" %in% TestColumnNames) && ("Label" %in% TestColumnNames)) {
LabelPredictionExist <- TRUE
tmp <- rxCube(~ F(Label):F(SDCA_Prediction), data = paste(strXDF, "Test_DS.xdf", sep = ""))
StatisticsResults <- Statistics(tmp, 3, paste(strXDF, "Training_DS.xdf", sep = ""))
remove(tmp)
sink("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Functions/Sink.R") 	#Starting sink-ing to Sink.R file
print(StatisticsResults)
sink()			#Stopping sink-ing
} else {
LabelPredictionExist <- FALSE
}
}
if (ShowROCCurve) {
## Graphs ##
if (("SDCA_Prediction" %in% TestColumnNames) && ("Label" %in% TestColumnNames)) {
PredictionRealExist <- TRUE
if (ColumnsCombinations) { #REngine can't handle multiple Plot Windows, hence they should be saved as PNG and ran afterwards
png(filename = paste(strGraphs, "EnsembleofDecisionTreesModelROC.png", sep = "") , width = 615, height = 520, units = "px")
}
rxRocCurve(actualVarName = "Label",
predVarName = "SDCA_PredictionReal",
data = paste(strXDF, "Test_DS.xdf", sep = "")
)
if (ColumnsCombinations) { #REngine can't handle multiple Plot Windows, hence they should be saved as PNG and ran afterwards
dev.off()
}
} else {
PredictionRealExist <- FALSE
}
}
}
remove(EnsembleofDecisionTreesModel)
type <- 'binary'
?rxNeuralNet
if (!(file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")) && (UseExistingModel)) {
RDSCreatedOutOfNecessity <- TRUE
} else {
RDSCreatedOutOfNecessity <- FALSE
}
if ((!(UseExistingModel)) || (!file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS"))) {
## Creating the Model ##
rxDTreeElapsedTime <- system.time(
#Tweakable:
#--Variables
#//To be left as is on this experiment (though tweakable if needed)\\#
#--normalize [auto/no/yes/warn]
NeuralNetworksModel <- rxNeuralNet(Label ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou + Skopos_Ergou + MelClientDelay + Mel_Kathisterisi_Pelati + MelDEHDelay + Mel_Kathisterisi_DEH + MelOthersDelay + Mel_Kathisterisi_Triton + Meres_Meletis + Sinergio_Meletis + Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis + Ektasi_Ergou + Anagi_YS + Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine + DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY + .rxCluster
, data = paste(strXDF, "Training_DS.xdf", sep = "")
,type = "binary"
,numHiddenNodes = 10 #The default number of hidden nodes in the neural net. The default value is 100
,numIterations = 10 #The number of iterations on the full training set. The default value is 100
,acceleration = acceleration #[sse/gpu]
,optimizer = sgd() #[sgd()/adaDeltaSgd()] A list specifying either the sgd or adaptive optimization algorithm. This list can be created using sgd or adaDeltaSgd. The default value is sgd.
,normalize = auto #[auto/no/yes/warn] "warn": if normalization is needed, a warning message is displayed, but normalization is not performed. Normalization rescales disparate data ranges to a standard scale. Feature scaling insures the distances between data points are proportional and enables various optimization methods such as gradient descent to converge much faster. If normalization is performed, a MaxMin normalizer is used. It normalizes values in an interval [a, b] where -1 <= a <= 0 and 0 <= b <= 1 and b - a = 1. This normalizer preserves sparsity by mapping zero to zero
# ,miniBatchSize = 1 #[1/256] Sets the mini-batch size. Recommended values are between 1 and 256. This parameter is only used when the acceleration is GPU. Setting this parameter to a higher value improves the speed of training, but it might negatively affect the accuracy. The default value is 1.
# ,netDefinition = #The Net# definition of the structure of the neural network. For more information about the Net# language, see https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-azure-ml-netsharp-reference-guide
# ,initWtsDiameter = 0.1 #Sets the initial weights diameter that specifies the range from which values are drawn for the initial learning weights. The weights are initialized randomly from within this range. The default value is 0.1.
# ,maxNorm = #Specifies an upper bound to constrain the norm of the incoming weight vector at each hidden unit. This can be very important in maxout neural networks as well as in cases where training produces unbounded weights
,reportProgress = rxGetOption('reportProgress')
,blocksPerRead = rxGetOption('blocksPerRead')
,rowSelection = NULL
)
)
# summary(NNModel) #The Neural Networks Model
} else {
NeuralNetworksModel <- readRDS("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")
}
acceleration <- 'sse'
if ((!(UseExistingModel)) || (!file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS"))) {
## Creating the Model ##
rxDTreeElapsedTime <- system.time(
#Tweakable:
#--Variables
#//To be left as is on this experiment (though tweakable if needed)\\#
#--normalize [auto/no/yes/warn]
NeuralNetworksModel <- rxNeuralNet(Label ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou + Skopos_Ergou + MelClientDelay + Mel_Kathisterisi_Pelati + MelDEHDelay + Mel_Kathisterisi_DEH + MelOthersDelay + Mel_Kathisterisi_Triton + Meres_Meletis + Sinergio_Meletis + Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis + Ektasi_Ergou + Anagi_YS + Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine + DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY + .rxCluster
, data = paste(strXDF, "Training_DS.xdf", sep = "")
,type = "binary"
,numHiddenNodes = 10 #The default number of hidden nodes in the neural net. The default value is 100
,numIterations = 10 #The number of iterations on the full training set. The default value is 100
,acceleration = acceleration #[sse/gpu]
,optimizer = sgd() #[sgd()/adaDeltaSgd()] A list specifying either the sgd or adaptive optimization algorithm. This list can be created using sgd or adaDeltaSgd. The default value is sgd.
,normalize = auto #[auto/no/yes/warn] "warn": if normalization is needed, a warning message is displayed, but normalization is not performed. Normalization rescales disparate data ranges to a standard scale. Feature scaling insures the distances between data points are proportional and enables various optimization methods such as gradient descent to converge much faster. If normalization is performed, a MaxMin normalizer is used. It normalizes values in an interval [a, b] where -1 <= a <= 0 and 0 <= b <= 1 and b - a = 1. This normalizer preserves sparsity by mapping zero to zero
# ,miniBatchSize = 1 #[1/256] Sets the mini-batch size. Recommended values are between 1 and 256. This parameter is only used when the acceleration is GPU. Setting this parameter to a higher value improves the speed of training, but it might negatively affect the accuracy. The default value is 1.
# ,netDefinition = #The Net# definition of the structure of the neural network. For more information about the Net# language, see https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-azure-ml-netsharp-reference-guide
# ,initWtsDiameter = 0.1 #Sets the initial weights diameter that specifies the range from which values are drawn for the initial learning weights. The weights are initialized randomly from within this range. The default value is 0.1.
# ,maxNorm = #Specifies an upper bound to constrain the norm of the incoming weight vector at each hidden unit. This can be very important in maxout neural networks as well as in cases where training produces unbounded weights
,reportProgress = rxGetOption('reportProgress')
,blocksPerRead = rxGetOption('blocksPerRead')
,rowSelection = NULL
)
)
# summary(NNModel) #The Neural Networks Model
} else {
NeuralNetworksModel <- readRDS("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")
}
if (!(file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")) && (UseExistingModel)) {
RDSCreatedOutOfNecessity <- TRUE
} else {
RDSCreatedOutOfNecessity <- FALSE
}
if ((!(UseExistingModel)) || (!file.exists("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS"))) {
## Creating the Model ##
rxDTreeElapsedTime <- system.time(
#Tweakable:
#--Variables
#//To be left as is on this experiment (though tweakable if needed)\\#
#--normalize [auto/no/yes/warn]
NeuralNetworksModel <- rxNeuralNet(Label ~ TimeSeriesDate
, data = paste(strXDF, "Training_DS.xdf", sep = "")
,type = "binary"
,numHiddenNodes = 500 #The default number of hidden nodes in the neural net. The default value is 100
,numIterations = 25 #The number of iterations on the full training set. The default value is 100
,acceleration = acceleration #[sse/gpu]
,optimizer = sgd() #[sgd()/adaDeltaSgd()] A list specifying either the sgd or adaptive optimization algorithm. This list can be created using sgd or adaDeltaSgd. The default value is sgd.
,normalize = "auto" #[auto/no/yes/warn] "warn": if normalization is needed, a warning message is displayed, but normalization is not performed. Normalization rescales disparate data ranges to a standard scale. Feature scaling insures the distances between data points are proportional and enables various optimization methods such as gradient descent to converge much faster. If normalization is performed, a MaxMin normalizer is used. It normalizes values in an interval [a, b] where -1 <= a <= 0 and 0 <= b <= 1 and b - a = 1. This normalizer preserves sparsity by mapping zero to zero
# ,miniBatchSize = 1 #[1/256] Sets the mini-batch size. Recommended values are between 1 and 256. This parameter is only used when the acceleration is GPU. Setting this parameter to a higher value improves the speed of training, but it might negatively affect the accuracy. The default value is 1.
# ,netDefinition = #The Net# definition of the structure of the neural network. For more information about the Net# language, see https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-azure-ml-netsharp-reference-guide
# ,initWtsDiameter = 0.1 #Sets the initial weights diameter that specifies the range from which values are drawn for the initial learning weights. The weights are initialized randomly from within this range. The default value is 0.1.
# ,maxNorm = #Specifies an upper bound to constrain the norm of the incoming weight vector at each hidden unit. This can be very important in maxout neural networks as well as in cases where training produces unbounded weights
,reportProgress = rxGetOption('reportProgress')
,blocksPerRead = rxGetOption('blocksPerRead')
,rowSelection = NULL
)
)
# summary(NNModel) #The Neural Networks Model
} else {
NeuralNetworksModel <- readRDS("C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")
}
if (SavePredictionModel) {
saveRDS(NeuralNetworksModel, "C:/Users/GiannisM/Dropbox/AUTH/Thesis/Source Code/HEDNO Oracle/HEDNO Oracle/bin/Debug/Models/NeuralNetworksModel.RDS")
}
if (MakePredictions) {
## Applying the Predictions ##
rxPredict(modelObject = NeuralNetworksModel,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "tmp.xdf", sep = ""),
overwrite = TRUE
)
if (type == "binary") {
tmpVarInfo <- list(
PredictedLabel = list(newName = "SDCA_Prediction"),
Probability.1 = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
varsToKeep = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
} else {
tmpVarInfo <- list(
Score = list(newName = "SDCA_PredictionReal")
)
rxSetVarInfo(varInfo = tmpVarInfo,
data = paste(strXDF, "tmp.xdf", sep = "")
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "tmp2.xdf", sep = ""),
transforms = list(SDCA_Prediction = ifelse(SDCA_PredictionReal >= 0.5, 1, 0)),
overwrite = TRUE
)
}
CurVarNamesTest <- rxSummary(~., data = paste(strXDF, "Test_DS.xdf", sep = ""))$sDataFrame[[1]]
if ("SDCA_PredictionReal" %in% (CurVarNamesTest)) {
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "tmp3.xdf", sep = ""),
varsToDrop = c("SDCA_PredictionReal", "SDCA_Prediction"),
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp3.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
file.remove(paste(strXDF, "tmp3.xdf", sep = ""))
}
remove(CurVarNamesTest)
rxMerge(inData1 = paste(strXDF, "Test_DS.xdf", sep = ""),
inData2 = paste(strXDF, "tmp2.xdf", sep = ""),
outFile = paste(strXDF, "tmp.xdf", sep = ""),
type = "oneToOne",
overwrite = TRUE
)
Test_DS <- rxImport(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
remove(tmpVarInfo)
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
file.remove(paste(strXDF, "tmp2.xdf", sep = ""))
if (!(StatisticsMode)) {
tmp <- rxDataStep(inData = Test_DS, varsToKeep = c("ID_Erga", "SDCA_PredictionReal", "SDCA_Prediction"))
write.csv(tmp, file = paste(strXDF, "NeuralNetworks_Results.csv", sep = ""), row.names = FALSE)
remove(tmp)
}
}
?rxDTreeElapsedTime
library(RevoTreeView) #No installation needed, is already installed
library(MicrosoftML)  #No installation needed, is already installed
?rxDTreeElapsedTime
#Loading required Libraries
library(rpart) #No installation needed, is already installed
library(rpart.plot)
library(rattle)
library(RevoTreeView) #No installation needed, is already installed
library(MicrosoftML)  #No installation needed, is already installed
#Determines how many blocks/chunks will be. For a dataset with 20,000 rows, there will only be 1 chunk, whilst for one with 133,098 like ours, where will be Ceil(133,098/20,000)=7 chunks
RowsPerRead = 20000
strXDF = "H:/[XDF]/"
#strDesktop = gsub("\\", "/", file.path(Sys.getenv("USERPROFILE"), "Desktop", fsep = "\\"), fixed = TRUE)
sqlConnString <- "driver={SQL Server};server=GIANNISM-PC;database=YLIKA_KOSTOL;trusted_connection=true"
?rxLogisticRegression
?initWtsScale
?rxLogisticRegression
remove(rocOut)
remove(TestDataSummary)
remove(a)
remove(Classification_DS)
remove(Clustering_DS)
remove(ClusteringSQLQuery)
remove(FP)
remove(FN)
remove(TP)
remove(TN)
remove(lil)
remove(irow)
remove(curNames)
remove(FirstNum)
remove(ColumnsCombinations)
remove(GraphOnFile)
remove(HasClustering)
remove(LabelPredictionExist)
remove(LogisticRegressionModel)
remove(LogisticRegressionModel3)
remove(MakePredictions)
remove(overwrite)
remove(PredictionRealExist)
remove(RDSCreatedOutOfNecessity)
remove(rxLogitElapsedTime)
remove(ShowDataSummary)
remove(ShowStatistics)
remove(SavePredictionModel)
remove(ShowROCCurve)
remove(ShowVariableInfo)
remove(StatisticsMode)
remove(StatisticsResults)
remove(Stats)
remove(Test_DS)
remove(TestColumnNames)
remove(UseExistingModel)
remove(whole)
remove(Training_DS)
remove(TestVarInfo)
Training_DS <- RxXdfData(file = paste(strXDF, "Training_DS.xdf", sep = ""))
n_Train <- rxGetInfo(data = Training_DS)$numRows
Test_DS <- RxXdfData(file = paste(strXDF, "Test_DS.xdf", sep = ""))
Classification_DS <- RxXdfData(paste(strXDF, "Classification_DS", sep = ""))
n_Classification <- rxGetInfo(data = Classification_DS)$numRows
