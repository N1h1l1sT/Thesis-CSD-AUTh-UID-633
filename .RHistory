rxGetInfo(paste(strXDF, "Mel_Ylika_DS.xdf", sep = ""), getVarInfo = TRUE, numRows = 5)
rxSummary(~., data = paste(strXDF, "Mel_Ylika_DS.xdf", sep = ""))$sDataFrame
Mel_Kostol_Analys_Ylika_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM v2Mel_Kostol_Analys_Ylika", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Mel_Kostol_Analys_Ylika_DS.xdf", sep = ""),
stringsAsFactors = TRUE,
overwrite = TRUE
)
rxGetInfo(paste(strXDF, "Mel_Kostol_Analys_Ylika_DS.xdf", sep = ""), getVarInfo = TRUE, numRows = 5)
rxSummary(~., data = paste(strXDF, "Mel_Kostol_Analys_Ylika_DS.xdf", sep = ""))$sDataFrame
file.remove(paste(strXDF, "Mel_Kostol_Analys_Ylika_DS.xdf", sep = ""))
remove(Mel_Kostol_Analys_Ylika_DS)
Mel_Kostol_Variantes_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM v3Mel_Kostol_Variantes", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Mel_Kostol_Variantes_DS.xdf", sep = ""),
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
rxGetInfo(paste(strXDF, "Mel_Kostol_Variantes_DS", sep = ""), getVarInfo = TRUE, numRows = 5)
rxSummary(~., data = paste(strXDF, "Mel_Kostol_Variantes_DS", sep = ""))$sDataFrame
file.remove(paste(strXDF, "Mel_Kostol_Variantes_DS.xdf", sep = ""))
remove(Mel_Kostol_Variantes_DS)
Erga_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM v4Erga", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Erga_DS.xdf", sep = ""),
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
rxGetInfo(paste(strXDF, "Erga_DS.xdf", sep = ""), getVarInfo = TRUE, numRows = 5)
rxSummary(~., data = paste(strXDF, "Erga_DS.xdf", sep = ""))$sDataFrame
Erga_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM v4Erga", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Erga_DS.xdf", sep = ""),
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
1+1
rxGetInfo(paste(strXDF, "Erga_DS.xdf", sep = ""), getVarInfo = TRUE, numRows = 5)
rxSummary(~., data = paste(strXDF, "Erga_DS.xdf", sep = ""))$sDataFrame
file.remove(paste(strXDF, "Erga_DS.xdf", sep = ""))
remove(Erga_DS)
AIO_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM vAIO", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "AIO_DS.xdf", sep = ""),
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
Erga_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM ERGA", connectionString = sqlConnString, rowsPerRead = 5000),
outFile = paste(strXDF, "Erga_DS.xdf", sep = ""),
colClasses = vErgaColClasses,
colInfo = vErgaColInfo,
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
vErgaColClasses <- c(Mel_Kathisterisi_Pelati = "integer",
Mel_Kathisterisi_DEH = "integer",
Mel_Kathisterisi_Triton = "integer",
Meres_Meletis = "integer",
Kostos_Ergatikon_Kataskevis = "numeric",
Kostos_Ilikon_Kataskevis = "numeric",
Kostos_Kataskevis = "numeric",
Kostos_Ergolavikon_Epidosis = "numeric",
DayOfYearSine = "numeric",
DayOfYearCosine = "numeric",
DayOfYearCartesX = "numeric",
DayOfYearCartesY = "numeric",
Kathisterisi_AitisisKataxorisis = "integer",
Kathisterisi_Meletis = "integer",
Kathisterisi_Anagelias = "integer",
Label = "integer",
ID_Erga = "factor",
TimeSeriesDate = "factor",
GrafioEktelesisErgou = "factor",
Onoma_Polis = "factor",
GeoLocX = "numeric",
GeoLocY = "numeric",
Katigoria = "factor",
Xaraktirismos_Ergou = "factor",
Skopos_Ergou = "factor",
MelClientDelay = "factor",
MelDEHDelay = "factor",
MelOthersDelay = "factor",
Sinergio_Meletis = "factor",
Ektasi_Ergou = "factor",
Anagi_YS = "factor",
SAP_Typos_Pelati = "factor",
SAP_Eidos_Aitimatos = "factor"
)
vErgaColInfo <- list(#Xaraktirismos_Ergou = list(type = "factor", levels = c("EKMETALEFSI","EPENDISI"), newLevels = c("EKMETALEFSI", "EPENDISI")), #For some reason it returns 0 rows for this column
MelClientDelay = list(type = "factor", levels = c("0","1"), newLevels = c("Not_Delayed", "Delayed")),
MelDEHDelay = list(type = "factor", levels = c("0","1"), newLevels = c("Not_Delayed", "Delayed")),
MelOthersDelay = list(type = "factor", levels = c("0","1"), newLevels = c("Not_Delayed", "Delayed")),
Anagi_YS = list(type = "factor", levels = c("0","1"), newLevels = c("Not_Needed", "Needed"))#,
# TimeSeriesDate = list(type = "factor",
#                       levels = c("1930 Q1", "1947 Q4", "1998 Q2", "1998 Q3", "1998 Q4", "1999 Q2", "1999 Q4", "2000 Q1", "2000 Q4", "2001 Q1", "2001 Q2", "2001 Q3", "2001 Q4", "2002 Q1", "2002 Q2", "2002 Q3", "2002 Q4", "2003 Q1", "2003 Q2", "2003 Q3", "2003 Q4", "2004 Q1", "2004 Q2", "2004 Q3", "2004 Q4", "2005 Q1", "2005 Q2", "2005 Q3", "2005 Q4", "2006 Q1", "2006 Q2", "2006 Q3", "2006 Q4", "2007 Q1", "2007 Q2", "2007 Q3", "2007 Q4", "2008 Q1", "2008 Q2", "2008 Q3", "2008 Q4", "2009 Q1", "2009 Q2", "2009 Q3", "2009 Q4", "2010 Q1", "2010 Q2", "2010 Q3", "2010 Q4", "2011 Q1", "2011 Q2", "2011 Q3", "2011 Q4", "2012 Q1", "2012 Q2", "2012 Q3", "2012 Q4", "2013 Q1", "2013 Q2", "2013 Q3", "2013 Q4", "2014 Q1", "2014 Q2", "2014 Q3", "2014 Q4", "2015 Q1", "2015 Q2", "2015 Q3", "2015 Q4", "2016 Q1", "2016 Q2"),
#                       newLevels = c("0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68", "69", "70")
# )
)
vErga_DS <- rxImport(inData = RxOdbcData(sqlQuery = "SELECT * FROM v4Erga", connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "vErga_DS.xdf", sep = ""),
colClasses = vErgaColClasses,
colInfo = vErgaColInfo,
stringsAsFactors = TRUE,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
rxGetInfo(vErga_DS)
rxGetInfo(vErga_DS, getVarInfo = TRUE)
rxSummary(~., data = vErga_DS)$sDataFrame
rxLinePlot(formula = GeoLocY ~ GeoLocX,
data = vErga_DS,
type = "p"
)
ClusteringSQLQuery <- "SELECT * FROM [YLIKA_KOSTOL].[dbo].[v4Erga] WHERE (GeoLocX >= 18 AND GeolocX <= 29 AND GeoLocY >= 34 AND GeoLocY <= 42) AND (GeoLocX <> -1 and GeoLocY <> -1)"
Clustering_DS <- rxImport(inData = RxOdbcData(sqlQuery = ClusteringSQLQuery, connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
colClasses = vErgaColClasses,
colInfo = vErgaColInfo,
stringsAsFactors = TRUE,
varsToDrop = c("Onoma_Polis"),
overwrite = TRUE
)
rxGetVarInfo(Clustering_DS)
ClusteringSQLQuery <- "SELECT * FROM [YLIKA_KOSTOL].[dbo].[v4Erga] WHERE (GeoLocX >= 18 AND GeolocX <= 29 AND GeoLocY >= 34 AND GeoLocY <= 42) AND (GeoLocX <> -1 and GeoLocY <> -1)"
Clustering_DS <- rxImport(inData = RxOdbcData(sqlQuery = ClusteringSQLQuery, connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
colClasses = vErgaColClasses,
colInfo = vErgaColInfo,
stringsAsFactors = TRUE,
overwrite = TRUE
)
rxDataStep(inData = Clustering_DS,
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
varsToDrop = c("Onoma_Polis"),
overwrite = TRUE
)
rxGetVarInfo(Clustering_DS)
rxGetVarInfo(paste(strXDF, "Clustering_DS.xdf", sep = ""))
rxGetVarInfoXdf(paste(strXDF, "Clustering_DS.xdf", sep = ""))
rxGetVarInfo(paste(strXDF, "Clustering_DS.xdf", sep = ""))
rxDataStep(inData = paste(strXDF, "Clustering_DS.xdf", sep = ""),
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
varsToDrop = c("Onoma_Polis"),
overwrite = TRUE
)
rxGetVarInfo(paste(strXDF, "Clustering_DS.xdf", sep = ""))
ClusteringSQLQuery <- "SELECT * FROM [YLIKA_KOSTOL].[dbo].[v4Erga] WHERE (GeoLocX >= 18 AND GeolocX <= 29 AND GeoLocY >= 34 AND GeoLocY <= 42) AND (GeoLocX <> -1 and GeoLocY <> -1)"
Clustering_DS <- rxImport(inData = RxOdbcData(sqlQuery = ClusteringSQLQuery, connectionString = sqlConnString, rowsPerRead = RowsPerRead),
outFile = paste(strXDF, "tmp.xdf", sep = ""),
colClasses = vErgaColClasses,
colInfo = vErgaColInfo,
stringsAsFactors = TRUE,
overwrite = TRUE
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
varsToDrop = c("Onoma_Polis"),
overwrite = TRUE
)
rxGetVarInfo(paste(strXDF, "Clustering_DS.xdf", sep = ""))
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
varsToDrop = c("Onoma_Polis"),
overwrite = TRUE
)
remove(ClusteringSQLQuery)
file.remove(paste(strXDF, "vErga_DS.xdf", sep = ""))
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
remove(vErga_DS)
file.remove(paste(strXDF, "vErga_DS.xdf", sep = ""))
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
remove(vErga_DS)
remove(vErgaColClasses)
remove(vErgaColInfo)
remove(ClusteringSQLQuery)
rxSummary(~., data = Clustering_DS)$sDataFrame
Clustering_DS <- RxXdfData(paste(strXDF, "Clustering_DS.xdf", sep = ""))
rxSummary(~., data = Clustering_DS)$sDataFrame
rxLinePlot(GeoLocY ~ GeoLocX, Clustering_DS, type = "p")
unsupervisedLocationData1 <- rxDataStep(inData = Clustering_DS,
varsToKeep = c("GeoLocX", "GeoLocY")
)
WithinGroupsSquaredError <- (nrow(unsupervisedLocationData1) - 1) * sum(apply(unsupervisedLocationData1, 2, var))
for (i in 2:15) {
WithinGroupsSquaredError[i] <- sum(rxKmeans(formula = formula(~ GeoLocX + GeoLocY),
data = unsupervisedLocationData1,
numClusters = i,
algorithm = "lloyd"
)$withinss
)
}
remove(unsupervisedLocationData1)
remove(i)
plot(1:15,
WithinGroupsSquaredError,
type = "b",
xlab = "# of Clusters",
ylab = "Within Groups Sum of Squares"
)
remove(WithinGroupsSquaredError)
KMeansModel <- rxKmeans(formula = ~ GeoLocX + GeoLocY,
data = paste(strXDF, "Clustering_DS.xdf", sep = ""),
numClusters = 5,
outFile = paste(strXDF, "Clustering_DS.xdf", sep = ""),
algorithm = "lloyd",
blocksPerRead = 1,
overwrite = TRUE
)
KMeansModel
remove(KMeansModel)
rxLinePlot(GeoLocY ~ GeoLocX,
groups = .rxCluster,
data = paste(strXDF, "Clustering_DS.xdf", sep = ""),
type = "p"
)
Spaces <- function(NumOfSpaces) {
str <- ""
if (NumOfSpaces > 0) {
for (i in 1:NumOfSpaces) {
str = paste(str, " ", sep = "")
}
}
return(str)
}
ConfMatrix <- function(ActAndPredValues, RoundAt) {
TN <- ActAndPredValues$Counts[1]
FN <- ActAndPredValues$Counts[2]
FP <- ActAndPredValues$Counts[3]
TP <- ActAndPredValues$Counts[4]
MaxItemLength <- max(nchar(ActAndPredValues$Counts))
strConfMatrix <- paste(Spaces(nchar("Pred_Value  ")), "Actual_Value", Spaces(((2 * MaxItemLength) + nchar(paste("  "))) - nchar("Actual_Value")), sep = "")
strConfMatrix <- rbind(strConfMatrix, paste("Pred_Value  " , Spaces(MaxItemLength - 1) , "0  " , Spaces(MaxItemLength - 1) , "1", sep = ""))
strConfMatrix <- rbind(strConfMatrix, paste(Spaces(nchar("Pred_Value  ") - 3), "0  " , Spaces(MaxItemLength - nchar(TN)), TN, "  ",
Spaces(MaxItemLength - nchar(FN)), FN, sep = ""))
strConfMatrix <- rbind(strConfMatrix, paste(Spaces(nchar("Pred_Value  ") - 3), "1  " , Spaces(MaxItemLength - nchar(FP)), FP, "  ",
Spaces(MaxItemLength - nchar(TP)), TP, sep = ""))
ActAndPredValues <- as.data.frame(ActAndPredValues)
ActAndPredValues$Result <- c("True Negative", "False Negative", "False Positive", "True Positive")
ActAndPredValues$PCT <- round(ActAndPredValues$Counts / sum(ActAndPredValues$Counts), RoundAt) * 100
ActAndPredValues$Rates <- round(c(TN / (TN + FP),
FN / (FN + TP),
FP / (TN + FP),
TP / (FN + TP)), RoundAt)
names(ActAndPredValues) <- c("Actual Value", "Predicted Value", "Cases", "Results", "Percentage", "Rates")
retList <- list(strConfMatrix, ActAndPredValues)
return(retList)
}
ShowStatistics <- function(ActAndPredValues, RoundAt, DataVarOrPath) {
TN <- ActAndPredValues$Counts[1]
FN <- ActAndPredValues$Counts[2]
FP <- ActAndPredValues$Counts[3]
TP <- ActAndPredValues$Counts[4]
tmp <- rxSummary(~LabelFactorial, data = DataVarOrPath)$categorical
MaxClass <- max(tmp[[1]][[2]])
MinClass <- min(tmp[[1]][[2]])
P0 <- (TP + TN) / (TN + FN + FP + TP)
Ma <- ((TP + FP) * (TP + FN)) / (TN + FN + FP + TP)
Mb <- ((FN + TN) * (FP + TN)) / (TN + FN + FP + TP)
Pe <- (Ma + Mb) / (TN + FN + FP + TP)
Stat <- list(
ConfusionMatrix = ConfMatrix(ActAndPredValues, RoundAt),
TotalPredictionPercentages = data.frame(Correctly = round(100 * (TN + TP) / sum(ActAndPredValues$Counts), RoundAt),
Incorrectly = round(100 * (FN + FP) / sum(ActAndPredValues$Counts), RoundAt)),
Measures = data.frame(
#This is a weighted average of the true positive rate (recall) and precision, their harmonic mean.
#F-score, like recall and precision, only considers the so-called positive predictions, with recall being the probability of predicting just the positive class, precision being the probability of a positive prediction being correct, and F-score equating these probabilities under the effective assumption that the positive labels and the positive predictions should have the same distribution and prevalence
F1 = round((2 * TP) / ((2 * TP) + FP + FN), RoundAt),
#indicates the central tendency or typical value of a set of numbers
G1 = round(sqrt((TP / (TP + FP)) * (TP / (TP + FN))), RoundAt),
G2 = round(sqrt((((TP / (TP + FN) * (FP + TP) / (TN + FN + FP + TP)) / (TP / (TP + FN) * (FP + TP) / (TN + FN + FP + TP)) + (1 - (TN / (TN + FP))) * (1 - ((FP + TP) / (TN + FN + FP + TP))))) * (TP / (TP + FN))), RoundAt),
#Matthews correlation coefficient is a measure of the quality of binary classifications. The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between −1 and +1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and −1 indicates total disagreement between prediction and observation. is generally regarded as a balanced measure which can be used even if the classes are of very different sizes.
PhiMCC = round((((TP * TN) - (FP * FN)) / sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))), RoundAt),
#A measure of how well the classifier performed as compared to how well it would have performed simply by chance. In other words, a model will have a high Kappa score if there is a big difference between the accuracy and the null error rate.
CohensK = round((P0 - Pe) / (1 - Pe), RoundAt),
#Youden's J statistic (also called Youden's index). estimates the probability of an informed decision.
#Its value ranges from -1 to 1, and has a zero value when a diagnostic test gives the same proportion of positive results for groups with and without the disease, i.e the test is useless.
#Youden's index is often used in conjunction with Receiver Operating Characteristic (ROC) analysis.[2] The index is defined for all points of an ROC curve, and the maximum value of the index may be used as a criterion for selecting the optimum cut-off point when a diagnostic test gives a numeric rather than a dichotomous result.
YoudensJ = round((TP/(TP+FN)) + (TN/(TN+FP)) - 1, RoundAt)
),
Rates = data.frame(
#The accuracy paradox for predictive analytics states that predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. It may be better to avoid the accuracy metric in favor of other metrics such as precision and recall
#Overall, how often is the classifier correct?
Accuracy = round((TN + TP) / (TN + FN + FP + TP), RoundAt),
BalancedAccuracy = round(((TP / (TP + FN)) + (TN / (TN + FP))) / 2, RoundAt),
DetectionRate = round(TP / (TN + FN + FP + TP), RoundAt),
#Overall, how often is it wrong?
MisclassRate = round((FP + FN) / (TN + FN + FP + TP), RoundAt),
#When it's actually yes, how often does it predict yes?
SensitRecallTPR = round(TP / (TP + FN), RoundAt),
#When it's actually no, how often does it predict yes? The proportion of all negatives that still yield positive test outcomes, i.e., the conditional probability of a positive test result given an event that was not present.
FPR = round(FP / (FP + TN), RoundAt),
#When it's actually no, how often does it predict no?
SpecificityTNR = round(TN / (TN + FP), RoundAt),
#The proportion of positives which yield negative test outcomes with the test, i.e., the conditional probability of a negative test result given that the condition being looked for is present
FNR = round(FN / (FN + TP), RoundAt),
#A description of random errors, a measure of statistical variability; when it predicts yes, how often is it correct?
PrecisionPPV1 = round(TP / (TP + FP), RoundAt),
#Very similar to precision, except that it takes prevalence into account. In the case where the classes are perfectly balanced (meaning the prevalence is 50%), the positive predictive value (PPV) is equivalent to precision
PPV2 = round(((TP / (TP + FN) * (FP + TP) / (TN + FN + FP + TP)) / (TP / (TP + FN) * (FP + TP) / (TN + FN + FP + TP)) + (1 - (TN / (TN + FP))) * (1 - ((FP + TP) / (TN + FN + FP + TP)))), RoundAt),
#When it predicts no, how often is it correct
NPV1 = round(TN / (TN + FN), RoundAt),
#Very similar to precision, except that it takes prevalence into account. In the case where the classes are perfectly balanced (meaning the prevalence is 50%), the negative predictive value (NPV2) is equivalent to NPV1
NPV2 = round((TN / (TN + FP) * (1 - (FP + TP) / (TN + FN + FP + TP))) / ((1 - TP / (TP + FN)) * (FP + TP) / (TN + FN + FP + TP) + TN / (TN + FP) * (1 - (FP + TP) / (TN + FN + FP + TP))), RoundAt),
#A way of conceptualizing the rate of type I errors in null hypothesis testing when conducting multiple comparisons
FDR = round(FP / (FP + TP), RoundAt),
#The accuracy paradox for predictive analytics states that predictive models with a given level of accuracy may have greater predictive power than models with higher accuracy. It may be better to avoid the accuracy metric in favor of other metrics such as precision and recall
#This is how often you would be wrong if you always predicted the majority class. This can be a useful baseline metric to compare your classifier against. However, the best classifier for a particular application will sometimes have a higher error rate than the null error rate, as demonstrated by the Accuracy Paradox.
NullErrorRate = round(MinClass / MaxClass, RoundAt),
#How often does the yes condition actually occur in our sample?
Prevalence = round((FP + TP) / (TN + FN + FP + TP), RoundAt)
)
)
return(Stat)
}
rxDataStep(inData = paste(strXDF, "Clustering_DS.xdf", sep = ""),
outFile = paste(strXDF, "preClassification1_DS.xdf", sep = ""),
transforms = list(SelectionRatio = as.integer(runif(.rxNumRows,1,11)),
LabelFactorial = factor(Label, c(0,1))),
overwrite=TRUE
)
file.remove(paste(strXDF, "Clustering_DS.xdf", sep = ""))
remove(Clustering_DS)
rxDataStep(inData = paste(strXDF, "preClassification1_DS.xdf", sep = ""),
outFile = paste(strXDF, "preClassification2_DS.xdf", sep = ""),
varsToDrop = c("GeoLocX", "GeoLocY"),
overwrite = TRUE
)
file.remove(paste(strXDF, "preClassification1_DS.xdf", sep = ""))
preClassification2_DS <- RxXdfData(file = paste(strXDF, "preClassification2_DS.xdf", sep = ""))
ClassificationColInfo <- list("LabelFactorial" = list(type = "factor", levels = c("0", "1"), newLevels = c("Cancelled", "Approved")))
remove(ClassificationColInfo)
file.remove(paste(strXDF, "preClassification2_DS.xdf", sep = ""))
remove(preClassification2_DS)
rxHistogram(~LabelFactorial, data = Classification_DS)
tmp <- rxDataStep(inData = Classification_DS,
varsToKeep = c("SelectionRatio")
)
ActualTrainingPercentage <- length(subset(tmp$SelectionRatio, tmp$SelectionRatio <= 8)) / nrow(tmp) * 100
ActualTrainingPercentage
rxDataStep(inData = paste(strXDF, "Classification_DS.xdf", sep = ""),
outFile = paste(strXDF, "Training_DS.xdf", sep = ""),
rowSelection = SelectionRatio <= 8, #About 80% of the data
varsToDrop = "SelectionRatio",
blocksPerRead = 20,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
Training_DS <- RxXdfData(file = paste(strXDF, "Training_DS.xdf", sep = ""))
ActualTestPercentage <- length(subset(tmp$SelectionRatio, tmp$SelectionRatio > 8)) / nrow(tmp) * 100
ActualTestPercentage
remove(tmp) #It is of no use after this, so removing it.
rxDataStep(inData = paste(strXDF, "Classification_DS.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
rowSelection = SelectionRatio > 8, #About 20% of the data
varsToDrop = "SelectionRatio",
blocksPerRead = 20,
rowsPerRead = RowsPerRead,
overwrite = TRUE
)
Test_DS <- RxXdfData(file = paste(strXDF, "Test_DS.xdf", sep = ""))
remove(ActualTestPercentage)
remove(ActualTrainingPercentage)
system.time(
LogisticRegressionModel <- rxLogit(Label ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou
+ Skopos_Ergou + MelClientDelay + MelDEHDelay + MelOthersDelay + Sinergio_Meletis
+ Ektasi_Ergou + Anagi_YS #+ SAP_Typos_Pelati #+ SAP_Eidos_Aitimatos
+ Mel_Kathisterisi_Pelati + Mel_Kathisterisi_DEH + Mel_Kathisterisi_Triton + Meres_Meletis
+ Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis
+ Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine
+ DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY
, data = paste(strXDF, "Training_DS.xdf", sep = ""),
reportProgress = rxGetOption("reportProgress")
)
)
summary(LogisticRegressionModel)
rxPredict(modelObject = LogisticRegressionModel,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "Test_DS.xdf", sep = ""),
overwrite = TRUE,
predVarNames = "LogRe_PredictionReal"
)
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
transforms = list(LogRe_Prediction = as.logical(round(LogRe_PredictionReal))),
overwrite = TRUE
)
tmp <- rxCube(~ F(Label):F(LogRe_Prediction), data = paste(strXDF, "Test_DS.xdf", sep = ""))
ShowStatistics(tmp, 3, paste(strXDF, "Training_DS.xdf", sep = ""))
remove(tmp)
rxRocCurve(actualVarName = "Label",
predVarName = "LogRe_PredictionReal",
data = paste(strXDF, "Test_DS.xdf", sep = "")
)
remove(LogisticRegressionModel)
system.time(
#The total number of passes through the data is equal to a base of maxDepth + 3, plus xVal times (maxDepth + 2), where xVal is the number of folds for cross-validation and maxDepth is the maximum tree depth.
#Scaling decision trees to very large data sets is possible with rxDTree but should be done with caution—the wrong choice of model parameters can easily lead to models that take hours or longer to estimate, even in a distributed computing environment. For example, in the Getting Started Guide, we estimated linear models using the big airline data and used the variable Origin as a predictor in several models. The Origin variable is a factor variable with 373 levels with no obvious ordering. Incorporating this variable into an rxDTree model that is performing more than two level classification can easily consume hours of computation time. To prevent such unintended consequences, rxDTree has a parameter maxUnorderedLevels which defaults to 32; in the case of Origin, this parameter would flag an error. However, a factor variable of “Region” which groups the airports of Origin by location may well be a useful proxy, and can be constructed to have only a limited number of levels. Numeric and ordered factor predictors are much more easily incorporated into the model.
#The rxDTree function has a number of options for controlling the model fit. Most of these control parameters will be familiar to rpart users, but the defaults have been modified in some cases to better support large data tree models. A full listing of these options can be found in the rxDTree help file, but the following have been found in our testing to be the most useful at controlling the time required to fit a model with rxDTree:
TreeModel <- rxDTree(LabelFactorial ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou
+ Skopos_Ergou + MelClientDelay + MelDEHDelay + MelOthersDelay + Sinergio_Meletis
+ Ektasi_Ergou + Anagi_YS #+ SAP_Typos_Pelati #+ SAP_Eidos_Aitimatos
+ Mel_Kathisterisi_Pelati + Mel_Kathisterisi_DEH + Mel_Kathisterisi_Triton + Meres_Meletis
+ Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis
+ Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine
+ DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY
,data = paste(strXDF, "Training_DS.xdf", sep = "")
,xVal = 10 #this controls the number of folds used to perform cross-validation. The default of 2 allows for some pruning; once you have closed in a model you may want to increase the value for final fitting and pruning.
,maxDepth = 15 #this sets the maximum depth of any node of the tree. Computations grow rapidly more expensive as the depth increases, so we recommend a maxDepth of 10 to 15.
,method = "anova"
,maxNumBins = 323 #this controls the maximum number of bins used for each variable. Managing the number of bins is important in controlling memory usage. The default is to use the larger of 101 and the square root of the number of observations for small to moderate size data sets (up to about one million observations), but for larger sets to use 1001 bins. For small data sets with continuous predictors, you may find that you need to increase the maxNumBins to obtain models that resemble those from rpart.
,xdfCompressionLevel = rxGetOption("xdfCompressionLevel")
,reportProgress = rxGetOption("reportProgress")
,blocksPerRead = rxGetOption("blocksPerRead")
,fweights = #If duplicate rows have been eliminated, creating a new variable of how many duplicate rows were, then this Variable/Column can be used as Frequency Weight
#,maxCompete = 0 #this specifies the number of “competitor splits” retained in the output. By default, rxDTree sets this to 0, but a setting of 3 or 4 can be useful for diagnostic purposes in determining why a particular split was chosen.
#,maxSurrogate = 0 #this specifies the number of surrogate splits retained in the output. Again, by default rxDTree sets this to 0. Surrogate splits are used to assign an observation when the primary split variable is missing for that observation.
#For large data sets (100000 or more observations), you may need to adjust the following parameters to obtain meaningful models:
#The default cp of 0 produces a very large number of splits; specifying cp = 1e-5 produces a more manageable set of splits in this model
,cp = 0 #this is a complexity parameter and sets the bar for how much a split must reduce the complexity before being accepted. We have set the default to 0 and recommend using maxDepth and minBucket to control your tree sizes. If you want to specify a cp value, start with a conservative value, such as rpart’s 0.01; if you don’t see an adequate number of splits, decrease the cp by powers of 10 until you do. For our large airline data, we have found interesting models begin with a cp of about 1e-4.
#,minSplit = #determines how many observations must be in a node before a split is attempted
#,minBucket =  #determines how many observations must remain in a terminal node.
)
)
TreeModel #The Tree model
printcp(rxAddInheritance(TreeModel)) #Table of optimal prunings based on complexity
plotcp(rxAddInheritance(TreeModel))
TreeModelPruned <- prune(TreeModel, cp=2.2416e-04)
rxPredict(modelObject = TreeModelPruned,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "Test_DS.xdf", sep = ""),
overwrite = TRUE,
predVarNames = "Tree_PredictionReal"
)
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
transforms = list(Tree_Prediction = as.logical(round(Tree_PredictionReal))),
overwrite = TRUE
)
rxSummary(~., data = paste(strXDF, "Test_DS.xdf", sep = ""))$sDataFrame
tmp <- rxCube(~ F(Label):F(Tree_Prediction), data = paste(strXDF, "Test_DS.xdf", sep = ""))
ShowStatistics(tmp, 3, paste(strXDF, "Test_DS.xdf", sep = ""))
remove(tmp)
rxRocCurve(actualVarName = "Label",
predVarName = "Tree_PredictionReal",
data = paste(strXDF, "Test_DS.xdf", sep = ""),
title = "Decision Tree ROC Curve",
chanceGridLine = TRUE,
computeAuc = TRUE
)
plot(createTreeView(TreeModel))
remove(TreeModel)
remove(TreeModelPruned)
system.time(
NaiveBayesModel <- rxNaiveBayes(LabelFactorial ~ TimeSeriesDate + GrafioEktelesisErgou + Katigoria + Xaraktirismos_Ergou
+ Skopos_Ergou + MelClientDelay + MelDEHDelay + MelOthersDelay + Sinergio_Meletis
+ Ektasi_Ergou + Anagi_YS #+ SAP_Typos_Pelati #+ SAP_Eidos_Aitimatos
+ Mel_Kathisterisi_Pelati + Mel_Kathisterisi_DEH + Mel_Kathisterisi_Triton + Meres_Meletis
+ Kostos_Ergatikon_Kataskevis + Kostos_Ilikon_Kataskevis + Kostos_Kataskevis + Kostos_Ergolavikon_Epidosis
+ Kathisterisi_AitisisKataxorisis + Kathisterisi_Meletis + Kathisterisi_Anagelias + DayOfYearSine
+ DayOfYearCosine + DayOfYearCartesX + DayOfYearCartesY
, data = paste(strXDF, "Training_DS.xdf", sep = ""),
smoothingFactor = 1
)
)
NaiveBayesModel #The Naive Bayes model
NB_Pred <- rxPredict(modelObject = NaiveBayesModel,
data = paste(strXDF, "Test_DS.xdf", sep = ""),
outData = paste(strXDF, "Test_DS.xdf", sep = ""),
overwrite = TRUE
,predVarNames = c("NBCancelledProbabil", "NB_PredictionReal")#, "tmpNB_Prediction")
, type="prob"
)
rxDataStep(inData = paste(strXDF, "Test_DS.xdf", sep = ""),
outFile = paste(strXDF, "tmp.xdf", sep = ""),
transforms = list(NB_Prediction = as.logical(round(NB_PredictionReal))),
overwrite = TRUE
)
rxDataStep(inData = paste(strXDF, "tmp.xdf", sep = ""),
outFile = paste(strXDF, "Test_DS.xdf", sep = ""),
varsToDrop = c("NBCancelledProbabil"),
overwrite = TRUE
)
file.remove(paste(strXDF, "tmp.xdf", sep = ""))
rxSummary(~., data = paste(strXDF, "Test_DS.xdf", sep = ""))$sDataFrame           #Naive Bayes has 35 missing values on its output
tmp <- rxCube(~ F(LabelFactorial):F(NB_Prediction), data = paste(strXDF, "Test_DS.xdf", sep = ""))
ShowStatistics(tmp, 3, paste(strXDF, "Test_DS.xdf", sep = ""))
remove(tmp)
rocOut <- rxRoc(actualVarName = "Label",
predVarName = c("LogRe_PredictionReal", "Tree_PredictionReal", "NB_PredictionReal"),
# predVarName = c("Tree_PredictionReal"),
# predVarName = c("Tree_PredictionReal",
#                 "Tree_PredictionRealAnoMl5",
#                 "Tree_PredictionRealAnoMl40",
#                 "Tree_PredictionRealAnoMl250",
#                 "Tree_PredictionRealAnoMl1000",
#                 "Tree_PredictionRealClMl5",
#                 "Tree_PredictionRealClMl5F",
#                 "Tree_PredictionRealClMl40",
#                 "Tree_PredictionRealClMl40F",
#                 "Tree_PredictionRealClMl250",
#                 "Tree_PredictionRealClMl1000F",
#                 "Tree_PredictionRealClMl1000"),
data = paste(strXDF, "Test_DS.xdf", sep = "")
)
rocOut
rxAuc(rocOut)
plot(rocOut,
title = "ROC Curve for Label",
lineStyle = c("solid", "twodash", "dashed")
)
remove(rocOut)
remove(NaiveBayesModel)
